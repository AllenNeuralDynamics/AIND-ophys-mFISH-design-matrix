{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Purpose:\n",
    "- Assume data is searched and loaded (develop this part later)\n",
    "    - Use data from \"Saffron\" (721291)\n",
    "- Run design matrix, per session\n",
    "- Test attaching ophys data as well (consider memory limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DesignMatrix import DesignMatrix\n",
    "from comb.behavior_ophys_dataset import BehaviorOphysDataset, BehaviorMultiplaneOphysDataset\n",
    "from comb.behavior_session_dataset import BehaviorSessionDataset\n",
    "import os\n",
    "import glob\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import json\n",
    "\n",
    "# notebook dev\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import capsule_utils\n",
    "import load_data\n",
    "import design_matrix_tools as dmtools\n",
    "import kernel_tools as ktools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File rig.json not found in /root/capsule/data/multiplane-ophys_721291_2024-05-16_08-57-00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/comb/src/comb/processing/stimulus/stimulus_processing.py:802: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  is_change = is_change.fillna(False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File rig.json not found in /root/capsule/data/multiplane-ophys_721291_2024-05-16_08-57-00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/comb/src/comb/processing/stimulus/stimulus_processing.py:802: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  is_change = is_change.fillna(False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File rig.json not found in /root/capsule/data/multiplane-ophys_721291_2024-05-16_08-57-00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/comb/src/comb/processing/stimulus/stimulus_processing.py:802: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  is_change = is_change.fillna(False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File rig.json not found in /root/capsule/data/multiplane-ophys_721291_2024-05-16_08-57-00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/comb/src/comb/processing/stimulus/stimulus_processing.py:802: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  is_change = is_change.fillna(False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File rig.json not found in /root/capsule/data/multiplane-ophys_721291_2024-05-16_08-57-00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/comb/src/comb/processing/stimulus/stimulus_processing.py:802: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  is_change = is_change.fillna(False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File rig.json not found in /root/capsule/data/multiplane-ophys_721291_2024-05-16_08-57-00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/comb/src/comb/processing/stimulus/stimulus_processing.py:802: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  is_change = is_change.fillna(False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File rig.json not found in /root/capsule/data/multiplane-ophys_721291_2024-05-16_08-57-00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/comb/src/comb/processing/stimulus/stimulus_processing.py:802: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  is_change = is_change.fillna(False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File rig.json not found in /root/capsule/data/multiplane-ophys_721291_2024-05-16_08-57-00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/comb/src/comb/processing/stimulus/stimulus_processing.py:802: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  is_change = is_change.fillna(False)\n"
     ]
    }
   ],
   "source": [
    "session_name = 'multiplane-ophys_721291_2024-05-16_08-57-00'\n",
    "\n",
    "data_dir = Path('/root/capsule/data/')\n",
    "raw_path = data_dir / session_name\n",
    "processed_path = list(data_dir.glob(f'{session_name}_processed*'))[0]\n",
    "\n",
    "opids = []\n",
    "for plane_folder in processed_path.glob(\"*\"):\n",
    "    if plane_folder.is_dir() and not plane_folder.stem.startswith(\"nextflow\"):\n",
    "        opid = plane_folder.stem\n",
    "        opids.append(opid)\n",
    "\n",
    "bod_list = []\n",
    "for opid in opids:\n",
    "    bod = load_data.load_plane_data(session_name, opid=opid)\n",
    "    bod = capsule_utils.add_trials_to_bod(bod)\n",
    "    bod_list.append(bod)\n",
    "bod = bod_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_input_kernels():\n",
    "    kernels = {\n",
    "        'intercept':    {'feature':'intercept',   'type':'continuous',    'length':0,     'offset':0,     'num_weights':None, 'dropout':True, 'text': 'constant value'},\n",
    "        'hits':         {'feature':'hit',         'type':'discrete',      'length':1.5,   'offset':0,    'num_weights':None, 'dropout':True, 'text': 'lick to image change'},\n",
    "        'misses':       {'feature':'miss',        'type':'discrete',      'length':1.5,   'offset':0,    'num_weights':None, 'dropout':True, 'text': 'no lick to image change'},\n",
    "        'passive_change':   {'feature':'passive_change','type':'discrete','length':1.5,   'offset':0,    'num_weights':None, 'dropout':True, 'text': 'passive session image change'},\n",
    "        #'hits':         {'feature':'hit',         'type':'discrete',      'length':.75,   'offset':0,    'num_weights':None, 'dropout':True, 'text': 'lick to image change'},\n",
    "        #'misses':       {'feature':'miss',        'type':'discrete',      'length':.75,   'offset':0,    'num_weights':None, 'dropout':True, 'text': 'no lick to image change'},\n",
    "        #'passive_change':   {'feature':'passive_change','type':'discrete','length':.75,   'offset':0,    'num_weights':None, 'dropout':True, 'text': 'passive session image change'},\n",
    "        #'post-hits':    {'feature':'hit',         'type':'discrete',      'length':1.5,   'offset':0.75,    'num_weights':None, 'dropout':True, 'text': 'lick to image change'},\n",
    "        #'post-misses':  {'feature':'miss',        'type':'discrete',      'length':1.5,   'offset':0.75,    'num_weights':None, 'dropout':True, 'text': 'no lick to image change'},\n",
    "        #'post-passive_change': {'feature':'passive_change','type':'discrete','length':1.5,   'offset':0.75,    'num_weights':None, 'dropout':True, 'text': 'passive session image change'},\n",
    "        'omissions':        {'feature':'omissions',   'type':'discrete',  'length':1.5,      'offset':0,     'num_weights':None, 'dropout':True, 'text': 'image was omitted'},\n",
    "        #'omissions':        {'feature':'omissions',   'type':'discrete',  'length':0.75,      'offset':0,     'num_weights':None, 'dropout':True, 'text': 'image was omitted'},\n",
    "        #'post-omissions':   {'feature':'omissions',   'type':'discrete',  'length':2.25,   'offset':0.75,  'num_weights':None, 'dropout':True, 'text': 'images after omission'},\n",
    "        'each-image':   {'feature':'each-image',  'type':'discrete',      'length':0.75,  'offset':0,     'num_weights':None, 'dropout':True, 'text': 'image presentation'},\n",
    "        'running':      {'feature':'running',     'type':'continuous',    'length':2,     'offset':-1,    'num_weights':None, 'dropout':True, 'text': 'normalized running speed'},\n",
    "        # 'pupil':        {'feature':'pupil',       'type':'continuous',    'length':2,     'offset':-1,    'num_weights':None, 'dropout':True, 'text': 'Z-scored pupil diameter'},\n",
    "        'licks':        {'feature':'licks',       'type':'discrete',      'length':2,     'offset':-1,    'num_weights':None, 'dropout':True, 'text': 'mouse lick'},\n",
    "        #'false_alarms':     {'feature':'false_alarm',   'type':'discrete','length':5.5,   'offset':-1,    'num_weights':None, 'dropout':True, 'text': 'lick on catch trials'},\n",
    "        #'correct_rejects':  {'feature':'correct_reject','type':'discrete','length':5.5,   'offset':-1,    'num_weights':None, 'dropout':True, 'text': 'no lick on catch trials'},\n",
    "        #'time':         {'feature':'time',        'type':'continuous',    'length':0,     'offset':0,    'num_weights':None,  'dropout':True, 'text': 'linear ramp from 0 to 1'},\n",
    "        #'beh_model':    {'feature':'beh_model',   'type':'continuous',    'length':.5,    'offset':-.25, 'num_weights':None,  'dropout':True, 'text': 'behavioral model weights'},\n",
    "        #'lick_bouts':   {'feature':'lick_bouts',  'type':'discrete',      'length':4,     'offset':-2,   'num_weights':None,  'dropout':True, 'text': 'lick bout'},\n",
    "        #'lick_model':   {'feature':'lick_model',  'type':'continuous',    'length':2,     'offset':-1,   'num_weights':None,  'dropout':True, 'text': 'lick probability from video'},\n",
    "        #'groom_model':  {'feature':'groom_model', 'type':'continuous',    'length':2,     'offset':-1,   'num_weights':None,  'dropout':True, 'text': 'groom probability from video'},\n",
    "    }\n",
    "    ## add face motion energy PCs\n",
    "    # for PC in range(5):\n",
    "    #     kernels['face_motion_PC_{}'.format(PC)] = {'feature':'face_motion_PC_{}'.format(PC), 'type':'continuous', 'length':2, 'offset':-1, 'dropout':True, 'text':'PCA from face motion videos'}\n",
    "    \n",
    "    return kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using filtered events traces\n",
      "Interpolating neural signal onto stimulus aligned timestamps\n",
      "Using filtered events traces\n",
      "Interpolating neural signal onto stimulus aligned timestamps\n",
      "Using filtered events traces\n",
      "Interpolating neural signal onto stimulus aligned timestamps\n",
      "Using filtered events traces\n",
      "Interpolating neural signal onto stimulus aligned timestamps\n",
      "Using filtered events traces\n",
      "Interpolating neural signal onto stimulus aligned timestamps\n",
      "Using filtered events traces\n",
      "Interpolating neural signal onto stimulus aligned timestamps\n",
      "Using filtered events traces\n",
      "Interpolating neural signal onto stimulus aligned timestamps\n",
      "Using filtered events traces\n",
      "Interpolating neural signal onto stimulus aligned timestamps\n"
     ]
    }
   ],
   "source": [
    "run_params = {'data_type': 'filtered_events'}\n",
    "input_kernel_dict = build_input_kernels()\n",
    "\n",
    "\n",
    "response_list = []\n",
    "run_params_list = []\n",
    "for bod in bod_list:\n",
    "    run_params = ktools.process_kernels(input_kernel_dict, run_params, bod)\n",
    "    response, run_params = load_data.extract_and_annotate_ophys_plane(bod, run_params)\n",
    "    response_list.append(response)\n",
    "    run_params_list.append(run_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert all run_params are the same\n",
    "assert all([run_params == run_params_list[0] for run_params in run_params_list])\n",
    "timestamps = [r['timestamps'] for r in response_list]\n",
    "assert all([(ts == timestamps[0]).all() for ts in timestamps])\n",
    "timebins = [r['time_bins'] for r in response_list]\n",
    "assert all([(tb == timebins[0]).all() for tb in timebins])\n",
    "ophys_frame_rates = [r['ophys_frame_rate'] for r in response_list]\n",
    "assert ~np.diff(ophys_frame_rates).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run params should be the same across planes\n",
    "run_params = run_params_list[0]\n",
    "run_params['input_kernel_dict'] = input_kernel_dict  # add for future use\n",
    "\n",
    "# response session array from concatenating all planes\n",
    "response_session_arr = xr.concat([r['response_arr'] for r in response_list], dim='cell_roi_id')\n",
    "\n",
    "# set up a response dictionary for adding kernels\n",
    "response = {}\n",
    "response['response_arr'] = response_session_arr\n",
    "response['timestamps'] = timestamps[0]\n",
    "response['time_bins'] = timebins[0]\n",
    "response['ophys_frame_rate'] = ophys_frame_rates[0]\n",
    "\n",
    "# response archive for saving\n",
    "response_archive = [r['stimulus_interpolation'] for r in response_list]\n",
    "\n",
    "# response matrix for saving\n",
    "response_matrix = response['response_arr']\n",
    "\n",
    "# response info dictionary for saving\n",
    "response_info = {}\n",
    "response_info['timestamps'] = response['timestamps']\n",
    "response_info['time_bins'] = response['time_bins']\n",
    "response_info['ophys_frame_rate'] = response['ophys_frame_rate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Adding kernel: intercept\n",
      "    Adding kernel: hits\n",
      "    Adding kernel: misses\n",
      "    Adding kernel: omissions\n",
      "    Adding kernel: running\n",
      "                 : Mean Centering\n",
      "                 : Standardized to unit variance\n",
      "    Adding kernel: licks\n",
      "    Adding kernel: im000\n",
      "    Adding kernel: im031\n",
      "    Adding kernel: im035\n",
      "    Adding kernel: im045\n",
      "    Adding kernel: im054\n",
      "    Adding kernel: im073\n",
      "    Adding kernel: im075\n",
      "    Adding kernel: im106\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<DesignMatrix.DesignMatrix at 0x7f92f1b909d0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add kernels to the designMatrix class\n",
    "design = DesignMatrix(response['timestamps'], response['ophys_frame_rate'])\n",
    "dmtools.add_kernels(design, run_params, bod, response) # need the trace array for kernels like population mean or PC1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assertion\n",
    "X = design.get_X()\n",
    "assert X.shape[0] == response['response_arr'].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Trim based on the kernel offsets\n",
    "# # Do this during fitting, not here, because there will be a lot of response matrices with offset differences.\n",
    "# offsets = [int(w.split('_')[1]) for w in X.weights.values]\n",
    "# min_offset = min(min(offsets), 0)\n",
    "# max_offset = max(max(offsets), 0)\n",
    "# use_indices = range(max_offset, X.shape[0] + min_offset)  # min_offset is negative or 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save results\n",
    "- Save them to scratch folder for reuse.\n",
    "    - Consider dynamic saving (search and save if not searched) with dataAssets later.\n",
    "    - Try individual dataAsset conversion (manually).\n",
    "- Design matrix and response matrix should be saved separately.\n",
    "    - Design matrix results should have info about the final design matrix\n",
    "    - Versioning with incremental integers for now. \n",
    "        - Same version should have the same set of features.\n",
    "        - Even though initial feature request is the same, depending on the availability the results can vary\n",
    "        - If the difference is only with kernel length, we can load previous design matrix and change them directly.\n",
    "        - Think about this later.\n",
    "    - Design matrix results:\n",
    "        - run_params\n",
    "        - design matrix\n",
    "    - Response matrix results:\n",
    "        - Have dff, events, filtered_events in the folder name.\n",
    "        - response matrix\n",
    "        - response dictionary (combined across planes)\n",
    "        - response archive list of dictionary (across planes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[False, False, False, False, True, True, False]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = Path('/root/capsule/scratch/')\n",
    "\n",
    "session_save_path_desmat = save_path / f'design_matrix_{session_name}_00' # 00 just for the test\n",
    "session_save_path_desmat.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "data_type = run_params['data_type']\n",
    "session_save_path_resmat = save_path / f'response_matrix_{session_name}_{data_type}'\n",
    "session_save_path_resmat.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# serialize sets in run_params\n",
    "run_params_keys = list(run_params.keys())\n",
    "set_inds = np.where([type(run_params[key])==set for key in run_params_keys])[0]\n",
    "for i in set_inds:\n",
    "    key = run_params_keys[i]\n",
    "    run_params[key] = list(run_params[key])\n",
    "\n",
    "run_params_fn = session_save_path_desmat / 'run_params.json'\n",
    "with open(run_params_fn, 'w') as f:\n",
    "    json.dump(run_params, f, indent=4)\n",
    "\n",
    "design_matrix_fn = session_save_path_desmat / 'design_matrix.nc'\n",
    "X.to_netcdf(design_matrix_fn)\n",
    "\n",
    "response_matrix_fn = session_save_path_resmat / 'response_matrix.nc'\n",
    "response_matrix.to_netcdf(response_matrix_fn)\n",
    "\n",
    "response_info_fn = session_save_path_resmat / 'response_info.npz'\n",
    "np.savez(response_info_fn, response_info)\n",
    "    \n",
    "response_archive_fn = session_save_path_resmat / 'response_archive.npz'\n",
    "np.savez(response_archive_fn, response_archive)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
